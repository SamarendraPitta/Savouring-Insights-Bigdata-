{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef0934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a44fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "896cd76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize the SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")  # Replace with your MongoDB URI\n",
    "db = client[\"Project\"]  # Replace with your database name\n",
    "collection = db[\"pizza_business_feature_classification\"]  # Replace with your collection name\n",
    "\n",
    "# List of non-opinion related POS tags to filter out (nouns, pronouns, etc.)\n",
    "non_opinion_pos_tags = {'NN', 'NNS', 'NNP', 'NNPS', 'PRP', 'PRP$', 'IN'}\n",
    "\n",
    "# Stopwords to filter out (common words like 'we', 'the', etc.)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def filter_descriptors(descriptors):\n",
    "    \"\"\"\n",
    "    Filter out non-opinion words, repetitive descriptors, and stopwords.\n",
    "    Returns a list of valid descriptors for sentiment analysis.\n",
    "    \"\"\"\n",
    "    # Remove duplicates from descriptors\n",
    "    unique_descriptors = set(descriptors)\n",
    "\n",
    "    filtered_descriptors = []\n",
    "    for word in unique_descriptors:\n",
    "        # Remove stopwords and words with irrelevant POS tags (nouns, pronouns, prepositions, etc.)\n",
    "        if word.lower() not in stop_words and nltk.pos_tag([word])[0][1] not in non_opinion_pos_tags:\n",
    "            filtered_descriptors.append(word)\n",
    "\n",
    "    return filtered_descriptors\n",
    "\n",
    "def classify_descriptor_sentiment(descriptors):\n",
    "    \"\"\"\n",
    "    Classify sentiment of descriptors using VADER.\n",
    "    Returns a sentiment classification: positive, negative, or neutral.\n",
    "    \"\"\"\n",
    "    sentiment_result = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "    \n",
    "    filtered_descriptors = filter_descriptors(descriptors)\n",
    "    \n",
    "    for word in filtered_descriptors:\n",
    "        # Analyze the sentiment of the word\n",
    "        sentiment_score = sia.polarity_scores(word)\n",
    "        \n",
    "        # Classify sentiment based on VADER compound score\n",
    "        if sentiment_score['compound'] >= 0.05:\n",
    "            sentiment_result['positive'] += 1\n",
    "        elif sentiment_score['compound'] <= -0.05:\n",
    "            sentiment_result['negative'] += 1\n",
    "        else:\n",
    "            sentiment_result['neutral'] += 1\n",
    "    \n",
    "    return sentiment_result\n",
    "\n",
    "def calculate_sentiment_score(sentiment_counts):\n",
    "    \"\"\"\n",
    "    Calculate the score for each category (Food, Ambience, Service) based on sentiment classification.\n",
    "    Formula:\n",
    "        score = (positive - negative) / total descriptors\n",
    "    \"\"\"\n",
    "    total = sum(sentiment_counts.values())  # Total descriptors (positive + negative + neutral)\n",
    "    \n",
    "    # Handle the case where no descriptors are available\n",
    "    if total == 0:\n",
    "        return {'positive_score': 0, 'negative_score': 0, 'neutral_score': 0}\n",
    "    \n",
    "    positive_score = sentiment_counts['positive'] / total\n",
    "    negative_score = sentiment_counts['negative'] / total\n",
    "    neutral_score = sentiment_counts['neutral'] / total\n",
    "    \n",
    "    return {'positive_score': positive_score, 'negative_score': negative_score, 'neutral_score': neutral_score}\n",
    "\n",
    "def normalize_scores(results):\n",
    "    \"\"\"\n",
    "    Normalize the sentiment scores for each category (Food, Ambience, Service)\n",
    "    so that they are comparable across businesses.\n",
    "    \"\"\"\n",
    "    # Find the maximum descriptor count across all businesses for each category\n",
    "    max_scores = {\n",
    "        'positive_score': 0,\n",
    "        'negative_score': 0,\n",
    "        'neutral_score': 0\n",
    "    }\n",
    "    \n",
    "    # Find maximum scores for normalization\n",
    "    for business, categories in results.items():\n",
    "        for category, sentiment in categories.items():\n",
    "            # Handle the case where polarity_scores are missing or incomplete\n",
    "            if 'positive_score' in sentiment and 'negative_score' in sentiment and 'neutral_score' in sentiment:\n",
    "                max_scores['positive_score'] = max(max_scores['positive_score'], sentiment['positive_score'])\n",
    "                max_scores['negative_score'] = max(max_scores['negative_score'], sentiment['negative_score'])\n",
    "                max_scores['neutral_score'] = max(max_scores['neutral_score'], sentiment['neutral_score'])\n",
    "\n",
    "    # Normalize the scores for each business\n",
    "    for business, categories in results.items():\n",
    "        for category, sentiment in categories.items():\n",
    "            # Ensure we do not divide by zero\n",
    "            sentiment['positive_score'] /= max_scores['positive_score'] if max_scores['positive_score'] != 0 else 1\n",
    "            sentiment['negative_score'] /= max_scores['negative_score'] if max_scores['negative_score'] != 0 else 1\n",
    "            sentiment['neutral_score'] /= max_scores['neutral_score'] if max_scores['neutral_score'] != 0 else 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def adjust_polarity_scores(polarity_scores, neutral_weight_factor=0.5):\n",
    "    \"\"\"\n",
    "    Adjust the neutral score and redistribute the remaining weight\n",
    "    proportionally to positive and negative scores.\n",
    "    \"\"\"\n",
    "    # Adjust the neutral score\n",
    "    adjusted_neutral_score = polarity_scores[\"neutral_score\"] * neutral_weight_factor\n",
    "\n",
    "    # Calculate the remaining weight for positive and negative scores\n",
    "    remaining_weight = 1 - adjusted_neutral_score\n",
    "    total_positive_negative = polarity_scores[\"positive_score\"] + polarity_scores[\"negative_score\"]\n",
    "\n",
    "    if total_positive_negative == 0:\n",
    "        # If no positive or negative scores, assign all remaining weight to neutral\n",
    "        return {\n",
    "            \"positive_score\": 0,\n",
    "            \"negative_score\": 0,\n",
    "            \"neutral_score\": adjusted_neutral_score\n",
    "        }\n",
    "\n",
    "    # Calculate the ratios for positive and negative scores\n",
    "    positive_ratio = polarity_scores[\"positive_score\"] / total_positive_negative\n",
    "    negative_ratio = polarity_scores[\"negative_score\"] / total_positive_negative\n",
    "\n",
    "    # Redistribute the remaining weight\n",
    "    adjusted_positive_score = remaining_weight * positive_ratio\n",
    "    adjusted_negative_score = remaining_weight * negative_ratio\n",
    "\n",
    "    # Return the adjusted scores\n",
    "    return {\n",
    "        \"positive_score\": adjusted_positive_score,\n",
    "        \"negative_score\": adjusted_negative_score,\n",
    "        \"neutral_score\": adjusted_neutral_score,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def update_polarity_scores(business_data, neutral_weight_factor=0.5):\n",
    "    \"\"\"\n",
    "    Process each business, calculate and adjust polarity scores, and update them in MongoDB.\n",
    "    \"\"\"\n",
    "    for business in business_data:\n",
    "        feature_classification = business['feature_classification']\n",
    "\n",
    "        # Iterate over each category for sentiment calculation\n",
    "        for category, category_data in feature_classification.items():\n",
    "            features = category_data['features']\n",
    "            descriptors = category_data['descriptors']\n",
    "\n",
    "            # Classify sentiment for the descriptors\n",
    "            sentiment_counts = classify_descriptor_sentiment(descriptors)\n",
    "\n",
    "            # Calculate initial sentiment scores\n",
    "            sentiment_scores = calculate_sentiment_score(sentiment_counts)\n",
    "\n",
    "            # Adjust the sentiment scores using the provided logic\n",
    "            adjusted_scores = adjust_polarity_scores(sentiment_scores, neutral_weight_factor)\n",
    "\n",
    "            # Insert adjusted polarity scores into the MongoDB document for this category\n",
    "            collection.update_one(\n",
    "                {\"_id\": business[\"_id\"]},\n",
    "                {\"$set\": {\n",
    "                    f\"feature_classification.{category}.polarity_scores\": adjusted_scores\n",
    "                }}\n",
    "            )\n",
    "            #print(f\"Inserted adjusted polarity scores for {category} in {business['business_name']}\")\n",
    "\n",
    "\n",
    "# Fetch a limited number of documents from the collection\n",
    "business_data = list(collection.find().sort(\"_id\", -1))\n",
    "\n",
    "# Update adjusted polarity scores for the fetched businesses\n",
    "update_polarity_scores(business_data, neutral_weight_factor=0.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55122dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
